{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6a51f80",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T21:25:40.616487Z",
     "start_time": "2025-05-30T21:25:40.613681Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "sys.path.append(str(Path(os.getcwd()).parent))\n",
    "\n",
    "from copy import deepcopy\n",
    "import pandas as pd\n",
    "import yaml\n",
    "import torch\n",
    "from ipywidgets import widgets\n",
    "from matplotlib import pyplot as plt\n",
    "from seaborn import color_palette\n",
    "\n",
    "from gpa.common.helpers import plot_bboxes, parse_into_subgraphs\n",
    "from gpa.datasets.attribution import DetectionGraph\n",
    "from gpa.datasets.attribution import PriceAttributionDataset\n",
    "from gpa.configs import TrainingConfig\n",
    "from gpa.models.attributors import LightningPriceAttributor\n",
    "from gpa.common.helpers import connect_products_with_nearest_price_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a628c2f4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T21:25:55.307972Z",
     "start_time": "2025-05-30T21:25:40.629224Z"
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m----> 2\u001b[0m     chkp_path \u001b[38;5;241m=\u001b[39m Path(\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mInput a path to the model checkpoint: \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m chkp_path\u001b[38;5;241m.\u001b[39mexists() \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m chkp_path\u001b[38;5;241m.\u001b[39mis_file():\n\u001b[1;32m      4\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid checkpoint path. Please try again.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/src/delicious/gpa/.venv/lib/python3.10/site-packages/ipykernel/kernelbase.py:1282\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1280\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1281\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(msg)\n\u001b[0;32m-> 1282\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_input_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1283\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1284\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parent_ident\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1285\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_parent\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1286\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpassword\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1287\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/src/delicious/gpa/.venv/lib/python3.10/site-packages/ipykernel/kernelbase.py:1325\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1322\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1323\u001b[0m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[1;32m   1324\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted by user\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1325\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1326\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1327\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Message:\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    chkp_path = Path(input(\"Input a path to the model checkpoint: \"))\n",
    "    if not chkp_path.exists() or not chkp_path.is_file():\n",
    "        print(\"Invalid checkpoint path. Please try again.\")\n",
    "        continue\n",
    "    break\n",
    "\n",
    "while True:\n",
    "    config_path = Path(input(\"Input a path to the config file: \"))\n",
    "    if not config_path.exists() or not config_path.is_file():\n",
    "        print(\"Invalid config path. Please try again.\")\n",
    "        continue\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d47e6c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(config_path, \"r\") as f:\n",
    "    config = TrainingConfig(**yaml.safe_load(f))\n",
    "dataset_dir = Path(\"..\") / config.dataset_dir / \"val\"\n",
    "dataset = PriceAttributionDataset(root=dataset_dir)\n",
    "products_df = pd.read_csv(\n",
    "    dataset_dir / \"raw\" / \"product_boxes.csv\", index_col=\"attributionset_id\"\n",
    ")\n",
    "model = LightningPriceAttributor.load_from_checkpoint(chkp_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5a084cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.inference_mode()\n",
    "def plot_scene_graph(\n",
    "    idx: int,\n",
    "    dataset: PriceAttributionDataset,\n",
    "    model: LightningPriceAttributor,\n",
    "    threshold: float = 0.5,\n",
    "):\n",
    "    plt.close()\n",
    "    fig, axs = plt.subplots(1, 4, figsize=(15, 4), width_ratios=[1, 1, 1, 2])\n",
    "    graph: DetectionGraph = dataset[idx]\n",
    "\n",
    "    model.eval()\n",
    "    model.to(device=\"cpu\")\n",
    "    graph.to(device=\"cpu\")\n",
    "\n",
    "    actual_graph = deepcopy(graph)\n",
    "    actual_graph.edge_index = graph.gt_prod_price_edge_index\n",
    "    actual_graph.edge_attr = torch.ones(len(graph.gt_prod_price_edge_index[0]), 1)\n",
    "\n",
    "    heuristic_graph = deepcopy(graph)\n",
    "    src, dst = connect_products_with_nearest_price_tag(\n",
    "        centroids=graph.x[:, :2],\n",
    "        product_indices=graph.product_indices,\n",
    "        price_indices=graph.price_indices,\n",
    "    )\n",
    "    heuristic_graph.edge_index = torch.stack([src, dst], dim=0)\n",
    "    heuristic_graph.edge_attr = torch.ones(len(src), 1)\n",
    "    heuristic_graph.plot(ax=axs[0], prod_price_only=True, mark_wrong_edges=True)\n",
    "    axs[0].set_title(\"Heuristic\", fontsize=10)\n",
    "\n",
    "    edge_probs = model.forward(\n",
    "        x=graph.x,\n",
    "        edge_index=graph.edge_index,\n",
    "        edge_attr=graph.edge_attr,\n",
    "        src=src,\n",
    "        dst=dst,\n",
    "    ).sigmoid()\n",
    "    keep = edge_probs > threshold\n",
    "    graph.edge_index = torch.stack([src[keep], dst[keep]], dim=0)\n",
    "    graph.edge_attr = edge_probs[keep].view(-1, 1)\n",
    "    graph.plot(ax=axs[1], prod_price_only=True, mark_wrong_edges=True)\n",
    "    axs[1].set_title(\"Pruned\", fontsize=10)\n",
    "\n",
    "    actual_graph.plot(ax=axs[2], prod_price_only=True)\n",
    "    axs[2].set_title(\"Actual\", fontsize=10)\n",
    "\n",
    "    image_path = (\n",
    "        dataset_dir.parent / products_df.loc[graph.graph_id][\"local_path\"].values[0]\n",
    "    )\n",
    "    image = plt.imread(image_path)\n",
    "\n",
    "    height, width = image.shape[:2]\n",
    "\n",
    "    subgraph_indices = parse_into_subgraphs(\n",
    "        graph.gt_prod_price_edge_index, graph.num_nodes\n",
    "    )\n",
    "    subgraph_ids = torch.unique(subgraph_indices)\n",
    "    colors = color_palette(n_colors=len(subgraph_ids))\n",
    "    for i, color in zip(subgraph_ids, colors):\n",
    "        node_indices = torch.argwhere(subgraph_indices == i).flatten()\n",
    "        if len(node_indices) == 1:\n",
    "            color = (1.0, 1.0, 1.0)\n",
    "        product_indices = node_indices[torch.isin(node_indices, graph.product_indices)]\n",
    "        price_indices = node_indices[torch.isin(node_indices, graph.price_indices)]\n",
    "        plot_bboxes(\n",
    "            graph.x[product_indices, :4],\n",
    "            ax=axs[3],\n",
    "            color=color,\n",
    "            linestyle=\"solid\",\n",
    "            width=width,\n",
    "            height=height,\n",
    "        )\n",
    "        plot_bboxes(\n",
    "            graph.x[price_indices, :4],\n",
    "            ax=axs[3],\n",
    "            color=color,\n",
    "            linestyle=\"dashed\",\n",
    "            width=width,\n",
    "            height=height,\n",
    "        )\n",
    "\n",
    "    axs[3].imshow(image)\n",
    "    axs[3].axis(\"off\")\n",
    "\n",
    "    fig.tight_layout()\n",
    "    fig.set_dpi(100)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "760c87c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f11222b54212422695d741e4601b9053",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='Graph Index', max=188), FloatSlider(value=0.5, descriptiâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.<lambda>(idx, threshold)>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_func = lambda idx, threshold: plot_scene_graph(\n",
    "    idx=idx, dataset=dataset, model=model, threshold=threshold\n",
    ")\n",
    "idx_slider = widgets.IntSlider(\n",
    "    value=0, min=0, max=len(dataset) - 1, step=1, description=\"Graph Index\"\n",
    ")\n",
    "threshold_slider = widgets.FloatSlider(\n",
    "    value=0.5, min=0, max=1, step=0.01, description=\"Threshold\"\n",
    ")\n",
    "display(widgets.interact(display_func, idx=idx_slider, threshold=threshold_slider))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
